{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56733ad6-2e01-440a-b1f2-ab5fdb36a2c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Gradient boosted forest model\n",
    "Author: Roddy Jaques <br>\n",
    "*NHS Blood and Transplant*\n",
    "***\n",
    "## Assessing a gradient boosted forest model\n",
    "\n",
    "In this notebook models for the DBD and DCD cohorts are fit using a gradient boosted forest classifier.\n",
    "\n",
    "First, as usual, load in the data and create the training and test datasets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "349c70cd-a4aa-4d91-b5ba-ffeb4c7594af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sklearn.metrics as mets\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "# Function to print confusion matrix, balanced accuracy and accuracy for a set of actual and predicted labels\n",
    "def show_metrics(actual,predict):\n",
    "    \"\"\" Prints the confusion matrix, balanced accuracy and accuracy given datasets of actual and predicted labels\n",
    "    \n",
    "    Arguments:\n",
    "        actual - Dataset of actual labels\n",
    "        predict - Dataset of predicted labels\n",
    "     \"\"\"\n",
    "    cm = mets.confusion_matrix(actual, predict)\n",
    "    \n",
    "    print(\"********* MODEL METRIC REPORT *********\\n\\nConfusion matrix:\\n\")\n",
    "\n",
    "    print(\"TN  FN\\nFP  TP\\n\") #this is a reminder of what each part of the confusion matrix means e.g. TP = True Positive\n",
    "    \n",
    "    # print the confusion matrix\n",
    "    print(str(int(cm[0,0])) + \"    \" + str(int(cm[0,1])))\n",
    "    print(str(int(cm[1,0])) + \"    \" + str(int(cm[1,1])) + \"\\n\") \n",
    "\n",
    "    # classification report for DBD model\n",
    "    print(\"Classification report:\\n\")\n",
    "    print(mets.classification_report(actual, predict))\n",
    "\n",
    "    print(\"Balanced accuracy: \" + str(round(mets.balanced_accuracy_score(actual, predict),2)))\n",
    "\n",
    "    print(\"Accuracy: \" + str(round(mets.accuracy_score(actual, predict),2)))\n",
    "    \n",
    "    # Predicted vs actual consent rates\n",
    "    cons_rate = int(100 * len(actual[actual==\"Consent\"]) / len(actual) )\n",
    "    print(\"\\nActual consent rate: \" + str(cons_rate))\n",
    "    \n",
    "    pred_rate = int(100 * len(predict[predict==\"Consent\"]) / len(predict) )\n",
    "    print(\"Predicted consent rate: \" + str(pred_rate))\n",
    "    \n",
    "    pass\n",
    " \n",
    "# Function to format consent column from integer code to text\n",
    "def format_consent(x):\n",
    "    if x == 2:\n",
    "        return \"Consent\"\n",
    "    if x == 1:\n",
    "        return \"Non-consent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2971600f-bfdd-4da6-84a6-99da4e72fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in datasets \n",
    "dbd_model_data = pd.read_csv(\"Data/dbd_model_data.csv\")\n",
    "dcd_model_data = pd.read_csv(\"Data/dcd_model_data.csv\")\n",
    "\n",
    "# Columns used to create DBD model\n",
    "dbd_cols = [\"wish\", \"FORMAL_APR_WHEN\", \"donation_mentioned\", \"app_nature\", \"eth_grp\", \"religion_grp\", \"GENDER\", \"FAMILY_WITNESS_BSDT\", \"DTC_PRESENT_BSD_CONV\", \n",
    "            \"acorn_new\", \"adult\",\"FAMILY_CONSENT\"]\n",
    "\n",
    "dbd_model_data2 = pd.get_dummies(data=dbd_model_data,columns=dbd_cols[:-1],drop_first=True)\n",
    "\n",
    "dbd_features = dbd_model_data2.drop(\"FAMILY_CONSENT\",axis=1)\n",
    "dbd_consents = dbd_model_data2[\"FAMILY_CONSENT\"].apply(format_consent)\n",
    "\n",
    "# Columns used to create DCD model in paper\n",
    "dcd_cols = [\"wish\", \"donation_mentioned\", \n",
    "            \"app_nature\", \"eth_grp\", \"religion_grp\", \"GENDER\", \"DTC_WD_TRTMENT_PRESENT\", \n",
    "            \"acorn_new\", \"adult\",\"cod_neuro\",\"FAMILY_CONSENT\"]\n",
    "\n",
    "dcd_model_data2 = pd.get_dummies(data=dcd_model_data,columns=dcd_cols[:-1],drop_first=True)\n",
    "\n",
    "dcd_features = dcd_model_data2.drop(\"FAMILY_CONSENT\",axis=1)\n",
    "dcd_consents = dcd_model_data2[\"FAMILY_CONSENT\"].apply(format_consent)\n",
    "\n",
    "# creating a train and testing dataset for DBD and DCD approaches\n",
    "DBD_X_train, DBD_X_test, DBD_y_train, DBD_y_test = train_test_split(dbd_features,dbd_consents, test_size=0.33, random_state=10)\n",
    "\n",
    "DCD_X_train, DCD_X_test, DCD_y_train, DCD_y_test = train_test_split(dcd_features,dcd_consents, test_size=0.33, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf24aec-ab04-489b-a1a5-fd9dcfb4aab4",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br>\n",
    "Next, fit a Gradient boosted forest classifier to the DBD and DCD data with default hyperparameters.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67b8d836-2fa2-419a-b68d-345ec189ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting tree to training data \n",
    "boost_model = GradientBoostingClassifier()\n",
    "\n",
    "# fit to DBD training data \n",
    "DBD_boost = boost_model.fit(DBD_X_train,DBD_y_train)\n",
    "\n",
    "# predict and evaluate test data\n",
    "DBD_preds = DBD_boost.predict(DBD_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c6ada3a-8786-4e64-93b7-ce465e4dad2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* MODEL METRIC REPORT *********\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "TN  FN\n",
      "FP  TP\n",
      "\n",
      "1278    104\n",
      "384    234\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Consent       0.77      0.92      0.84      1382\n",
      " Non-consent       0.69      0.38      0.49       618\n",
      "\n",
      "    accuracy                           0.76      2000\n",
      "   macro avg       0.73      0.65      0.66      2000\n",
      "weighted avg       0.75      0.76      0.73      2000\n",
      "\n",
      "Balanced accuracy: 0.65\n",
      "Accuracy: 0.76\n",
      "\n",
      "Actual consent rate: 69\n",
      "Predicted consent rate: 83\n"
     ]
    }
   ],
   "source": [
    "# show metrics for DBD model\n",
    "show_metrics(DBD_y_test, DBD_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cb3d982-8a27-4319-a4de-1c89f23b4760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit to DCD training data\n",
    "DCD_boost = boost_model.fit(DCD_X_train,DCD_y_train)\n",
    "\n",
    "# fit and evalute DCD test data\n",
    "DCD_preds = DCD_boost.predict(DCD_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bd206b0-1828-474a-9fb5-5c4b21a1c126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* MODEL METRIC REPORT *********\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "TN  FN\n",
      "FP  TP\n",
      "\n",
      "1477    388\n",
      "449    790\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Consent       0.77      0.79      0.78      1865\n",
      " Non-consent       0.67      0.64      0.65      1239\n",
      "\n",
      "    accuracy                           0.73      3104\n",
      "   macro avg       0.72      0.71      0.72      3104\n",
      "weighted avg       0.73      0.73      0.73      3104\n",
      "\n",
      "Balanced accuracy: 0.71\n",
      "Accuracy: 0.73\n",
      "\n",
      "Actual consent rate: 60\n",
      "Predicted consent rate: 62\n"
     ]
    }
   ],
   "source": [
    "# print metrics for DCD model\n",
    "show_metrics(DCD_y_test, DCD_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e7a832-3abf-496e-9ee5-3be7c6d12217",
   "metadata": {},
   "source": [
    "***\n",
    "#### DBD model\n",
    "The DBD gradient boosted model has very low recall for the non-consents, worse than the logistic regression model (non-consent recall=0.44). And the balanced accuracy is lower than the logistic regression model's (BA = 0.67). \n",
    "\n",
    "The random forest model, even untuned, outperforms the boosted model, which is dissapointing given the reputation of boosted forest models. \n",
    "\n",
    "#### DCD model\n",
    "The DCD model here does slightly better than the logisitc regression, with a non-consent recall of 0.64, 0.02 higher then logitistic regression. This does perform better than the untuned random forest, on recall for both classes and overall balanced accuracy and accuracy. \n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf39f4e-7cc8-45f3-b238-ab831178da54",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "Tuning the hpyerparameters to try and improve the performance of the models. I'm using a cross validated gridsearch, optimising on balanced accuracy so that the balanced accuracy score isn't inflated by a high recall in the consent class.<br>\n",
    "For both models the hyper parameters and range of values to be explored are: <br>\n",
    "* max_depth - the maximum tree depth. From 1 to 200 in increments of 25.\n",
    "* n_estimators - the number of boosting stages. From 40 to 300 in increments of 30.\n",
    "* learning _rate - contribution of each tree to the ensemble. From 0.05 to 0.6 in increments of 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc1db117-96fb-42f4-a859-8918ec8af1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime = 45.0minutes\n",
      "{'learning_rate': 0.5500000000000002, 'max_depth': 26, 'n_estimators': 40}\n",
      "0.6461921506394411\n"
     ]
    }
   ],
   "source": [
    "# use a 5 fold cross validated grid search to find optimal hyperparameters\n",
    "cv_boost_model = GradientBoostingClassifier(random_state=66)\n",
    "\n",
    "# hyperparameters to test\n",
    "params = {'max_depth':np.arange(1,200,step=25),'n_estimators':np.arange(40,300,step=30),'learning_rate':np.arange(0.05,0.6,step=0.1)}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# train model for highest balanced accuracy\n",
    "dbd_gs_boost_model = GridSearchCV(cv_boost_model, param_grid=params, scoring=\"balanced_accuracy\",cv=5,n_jobs=3)\n",
    "\n",
    "dbd_gs_boost_model.fit(DBD_X_train,DBD_y_train)\n",
    "\n",
    "runtime = time.time() - start_time\n",
    "print(\"Runtime = {}minutes\".format(round(runtime/60,1)))\n",
    "\n",
    "# balanced accuracy of best model\n",
    "dbd_gs_boost_model.score(DBD_X_train,DBD_y_train)\n",
    "\n",
    "#\n",
    "print(dbd_gs_boost_model.best_params_)\n",
    "print(dbd_gs_boost_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cba9d661-1d59-4cfb-a095-ce75013bb73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* MODEL METRIC REPORT *********\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "TN  FN\n",
      "FP  TP\n",
      "\n",
      "1098    284\n",
      "313    305\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Consent       0.78      0.79      0.79      1382\n",
      " Non-consent       0.52      0.49      0.51       618\n",
      "\n",
      "    accuracy                           0.70      2000\n",
      "   macro avg       0.65      0.64      0.65      2000\n",
      "weighted avg       0.70      0.70      0.70      2000\n",
      "\n",
      "Balanced accuracy: 0.64\n",
      "Accuracy: 0.7\n",
      "\n",
      "Actual consent rate: 69\n",
      "Predicted consent rate: 70\n"
     ]
    }
   ],
   "source": [
    "# predict DBD test data consent\n",
    "DBD_preds = dbd_gs_boost_model.predict(DBD_X_test)\n",
    "\n",
    "# print metrics\n",
    "show_metrics(DBD_y_test,DBD_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80c82386-b383-41d6-a839-05434cb38115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime = 56.9minutes\n",
      "{'learning_rate': 0.25000000000000006, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.7012021321179738\n"
     ]
    }
   ],
   "source": [
    "# fit DCD model\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "dcd_gs_boost_model = GridSearchCV(cv_boost_model, param_grid=params, scoring=\"balanced_accuracy\",cv=5,n_jobs=3)\n",
    "\n",
    "dcd_gs_boost_model.fit(DCD_X_train,DCD_y_train)\n",
    "\n",
    "runtime = time.time() - start_time\n",
    "print(\"Runtime = {}minutes\".format(round(runtime/60,1)))\n",
    "\n",
    "dcd_gs_boost_model.score(DCD_X_train,DCD_y_train)\n",
    "\n",
    "print(dcd_gs_boost_model.best_params_)\n",
    "print(dcd_gs_boost_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c69514ca-a9ee-4ab1-bcce-03a46265e67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* MODEL METRIC REPORT *********\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "TN  FN\n",
      "FP  TP\n",
      "\n",
      "1471    394\n",
      "461    778\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Consent       0.76      0.79      0.77      1865\n",
      " Non-consent       0.66      0.63      0.65      1239\n",
      "\n",
      "    accuracy                           0.72      3104\n",
      "   macro avg       0.71      0.71      0.71      3104\n",
      "weighted avg       0.72      0.72      0.72      3104\n",
      "\n",
      "Balanced accuracy: 0.71\n",
      "Accuracy: 0.72\n",
      "\n",
      "Actual consent rate: 60\n",
      "Predicted consent rate: 62\n"
     ]
    }
   ],
   "source": [
    "DCD_preds = dcd_gs_boost_model.predict(DCD_X_test)\n",
    "\n",
    "# print metrics\n",
    "show_metrics(DCD_y_test,DCD_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200c7f43-e2e6-4af3-88be-847c7277e626",
   "metadata": {},
   "source": [
    "***\n",
    "#### Tuned DBD model\n",
    "The DBD gradient boosted model has very low recall for the non-consents, worse than the logistic regression model (non-consent recall=0.44). And the balanced accuracy is lower than the logistic regression model's (BA = 0.67). \n",
    "\n",
    "The random forest model, even untuned, has outperforms the boosted model, which is dissapointing given the reputation of boosted forest models. \n",
    "\n",
    "#### Tuned DCD model\n",
    "The DCD model here does slightly better than the logisitc regression, with a non-consent recall of 0.64, 0.02 higher then logitistic regression. This does perform better than the untuned random forest, on recall for both classes and overall balanced accuracy and accuracy. \n",
    "\n",
    "\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
