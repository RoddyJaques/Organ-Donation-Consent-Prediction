{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56733ad6-2e01-440a-b1f2-ab5fdb36a2c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Gradient boosted forest model\n",
    "Author: Roddy Jaques <br>\n",
    "*NHS Blood and Transplant*\n",
    "***\n",
    "## Assessing a gradient boosted forest model\n",
    "\n",
    "In this notebook models for the DBD and DCD cohorts are fit using a gradient boosted forest classifier.\n",
    "\n",
    "First, as usual, load in the data and create the training and test datasets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "349c70cd-a4aa-4d91-b5ba-ffeb4c7594af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sklearn.metrics as mets\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "# Function to print confusion matrix, balanced accuracy and accuracy for a set of actual and predicted labels\n",
    "def show_metrics(actual,predict):\n",
    "    \"\"\" Prints the confusion matrix, balanced accuracy and accuracy given datasets of actual and predicted labels\n",
    "    \n",
    "    Arguments:\n",
    "        actual - Dataset of actual labels\n",
    "        predict - Dataset of predicted labels\n",
    "     \"\"\"\n",
    "    cm = mets.confusion_matrix(actual, predict)\n",
    "    \n",
    "    print(\"********* MODEL METRIC REPORT *********\\n\\nConfusion matrix:\\n\")\n",
    "\n",
    "    print(\"TP  FN\\nFP  TN\\n\") #this is a reminder of what each part of the confusion matrix means e.g. TP = True Positive\n",
    "    \n",
    "    # print the confusion matrix\n",
    "    print(str(int(cm[0,0])) + \"    \" + str(int(cm[0,1])))\n",
    "    print(str(int(cm[1,0])) + \"    \" + str(int(cm[1,1])) + \"\\n\") \n",
    "\n",
    "    # classification report for DBD model\n",
    "    print(\"Classification report:\\n\")\n",
    "    print(mets.classification_report(actual, predict))\n",
    "\n",
    "    print(\"Balanced accuracy: \" + str(round(mets.balanced_accuracy_score(actual, predict),2)))\n",
    "\n",
    "    print(\"Accuracy: \" + str(round(mets.accuracy_score(actual, predict),2)))\n",
    "    \n",
    "    # Predicted vs actual consent rates\n",
    "    cons_rate = int(100 * len(actual[actual==\"Consent\"]) / len(actual) )\n",
    "    print(\"\\nActual consent rate: \" + str(cons_rate))\n",
    "    \n",
    "    pred_rate = int(100 * len(predict[predict==\"Consent\"]) / len(predict) )\n",
    "    print(\"Predicted consent rate: \" + str(pred_rate))\n",
    "    \n",
    "    pass\n",
    " \n",
    "# Function to format consent column from integer code to text\n",
    "def format_consent(x):\n",
    "    if x == 2:\n",
    "        return \"Consent\"\n",
    "    if x == 1:\n",
    "        return \"Non-consent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2971600f-bfdd-4da6-84a6-99da4e72fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in datasets \n",
    "dbd_model_data = pd.read_csv(\"Data/dbd_model_data.csv\")\n",
    "dcd_model_data = pd.read_csv(\"Data/dcd_model_data.csv\")\n",
    "\n",
    "# Columns used to create DBD model\n",
    "dbd_cols = [\"wish\", \"FORMAL_APR_WHEN\", \"donation_mentioned\", \"app_nature\", \"eth_grp\", \"religion_grp\", \"GENDER\", \"FAMILY_WITNESS_BSDT\", \"DTC_PRESENT_BSD_CONV\", \n",
    "            \"acorn_new\", \"adult\",\"FAMILY_CONSENT\"]\n",
    "\n",
    "dbd_model_data2 = pd.get_dummies(data=dbd_model_data,columns=dbd_cols[:-1],drop_first=True)\n",
    "\n",
    "dbd_features = dbd_model_data2.drop(\"FAMILY_CONSENT\",axis=1)\n",
    "dbd_consents = dbd_model_data2[\"FAMILY_CONSENT\"].apply(format_consent)\n",
    "\n",
    "# Columns used to create DCD model in paper\n",
    "dcd_cols = [\"wish\", \"donation_mentioned\", \n",
    "            \"app_nature\", \"eth_grp\", \"religion_grp\", \"GENDER\", \"DTC_WD_TRTMENT_PRESENT\", \n",
    "            \"acorn_new\", \"adult\",\"cod_neuro\",\"FAMILY_CONSENT\"]\n",
    "\n",
    "dcd_model_data2 = pd.get_dummies(data=dcd_model_data,columns=dcd_cols[:-1],drop_first=True)\n",
    "\n",
    "dcd_features = dcd_model_data2.drop(\"FAMILY_CONSENT\",axis=1)\n",
    "dcd_consents = dcd_model_data2[\"FAMILY_CONSENT\"].apply(format_consent)\n",
    "\n",
    "# creating a train and testing dataset for DBD and DCD approaches\n",
    "DBD_X_train, DBD_X_test, DBD_y_train, DBD_y_test = train_test_split(dbd_features,dbd_consents, test_size=0.33, random_state=10)\n",
    "\n",
    "DCD_X_train, DCD_X_test, DCD_y_train, DCD_y_test = train_test_split(dcd_features,dcd_consents, test_size=0.33, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf24aec-ab04-489b-a1a5-fd9dcfb4aab4",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br>\n",
    "Next, fit a Gradient boosted forest classifier to the DBD and DCD data with default hyperparameters.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67b8d836-2fa2-419a-b68d-345ec189ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting tree to training data \n",
    "boost_model = GradientBoostingClassifier()\n",
    "\n",
    "# fit to DBD training data \n",
    "DBD_boost = boost_model.fit(DBD_X_train,DBD_y_train)\n",
    "\n",
    "# predict and evaluate test data\n",
    "DBD_preds = DBD_boost.predict(DBD_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c6ada3a-8786-4e64-93b7-ce465e4dad2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* MODEL METRIC REPORT *********\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "TP  FN\n",
      "FP  TN\n",
      "\n",
      "1278    104\n",
      "384    234\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Consent       0.77      0.92      0.84      1382\n",
      " Non-consent       0.69      0.38      0.49       618\n",
      "\n",
      "    accuracy                           0.76      2000\n",
      "   macro avg       0.73      0.65      0.66      2000\n",
      "weighted avg       0.75      0.76      0.73      2000\n",
      "\n",
      "Balanced accuracy: 0.65\n",
      "Accuracy: 0.76\n",
      "\n",
      "Actual consent rate: 69\n",
      "Predicted consent rate: 83\n"
     ]
    }
   ],
   "source": [
    "# show metrics for DBD model\n",
    "show_metrics(DBD_y_test, DBD_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cb3d982-8a27-4319-a4de-1c89f23b4760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit to DCD training data\n",
    "DCD_boost = boost_model.fit(DCD_X_train,DCD_y_train)\n",
    "\n",
    "# fit and evalute DCD test data\n",
    "DCD_preds = DCD_boost.predict(DCD_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bd206b0-1828-474a-9fb5-5c4b21a1c126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* MODEL METRIC REPORT *********\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "TP  FN\n",
      "FP  TN\n",
      "\n",
      "1477    388\n",
      "449    790\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Consent       0.77      0.79      0.78      1865\n",
      " Non-consent       0.67      0.64      0.65      1239\n",
      "\n",
      "    accuracy                           0.73      3104\n",
      "   macro avg       0.72      0.71      0.72      3104\n",
      "weighted avg       0.73      0.73      0.73      3104\n",
      "\n",
      "Balanced accuracy: 0.71\n",
      "Accuracy: 0.73\n",
      "\n",
      "Actual consent rate: 60\n",
      "Predicted consent rate: 62\n"
     ]
    }
   ],
   "source": [
    "# print metrics for DCD model\n",
    "show_metrics(DCD_y_test, DCD_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e7a832-3abf-496e-9ee5-3be7c6d12217",
   "metadata": {},
   "source": [
    "***\n",
    "#### DBD model\n",
    "The DBD gradient boosted model has a recall of 0.38 for non-consents, lower than the logistic regression model non-consent recall of 0.44. The balanced accuracy is 0.71, also lower than the logistic regression model's balanced accuracy of 0.67. \n",
    "\n",
    "The random forest model, even untuned, outperforms the boosted model. \n",
    "\n",
    "#### DCD model\n",
    "The DCD model has a balanced accuracy of 0.71, higher than the logistic regression model's balanced accuracy but lower than the random forest. \n",
    "\n",
    "In this model the consent and non-consent recalls are more balanced than the random forest, and the difference between the actual and predicted consent rates are more similar than the random forest model.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf39f4e-7cc8-45f3-b238-ab831178da54",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "A cross validated gridsearch, optimising on balanced accuracy so that the balanced accuracy score isn't inflated by a high recall in the consent class.<br>\n",
    "For both models the hyper parameters and range of values to be explored are: <br>\n",
    "* max_depth - the maximum tree depth. From 1 to 200 in increments of 25.\n",
    "* n_estimators - the number of boosting stages. From 40 to 300 in increments of 30.\n",
    "* learning _rate - contribution of each tree to the ensemble. From 0.05 to 0.6 in increments of 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc1db117-96fb-42f4-a859-8918ec8af1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime = 35.8minutes\n",
      "{'learning_rate': 0.25000000000000006, 'max_depth': 26, 'n_estimators': 130}\n",
      "0.6457502156474684\n"
     ]
    }
   ],
   "source": [
    "# use a 5 fold cross validated grid search to find optimal hyperparameters\n",
    "cv_boost_model = GradientBoostingClassifier(random_state=66)\n",
    "\n",
    "# hyperparameters to test\n",
    "params = {'max_depth':np.arange(1,200,step=25),'n_estimators':np.arange(40,300,step=30),'learning_rate':np.arange(0.05,0.6,step=0.1)}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# train model for highest balanced accuracy\n",
    "dbd_gs_boost_model = GridSearchCV(cv_boost_model, param_grid=params, scoring=\"balanced_accuracy\",cv=5,n_jobs=3)\n",
    "\n",
    "dbd_gs_boost_model.fit(DBD_X_train,DBD_y_train)\n",
    "\n",
    "runtime = time.time() - start_time\n",
    "print(\"Runtime = {}minutes\".format(round(runtime/60,1)))\n",
    "\n",
    "# balanced accuracy of best model\n",
    "dbd_gs_boost_model.score(DBD_X_train,DBD_y_train)\n",
    "\n",
    "#\n",
    "print(dbd_gs_boost_model.best_params_)\n",
    "print(dbd_gs_boost_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cba9d661-1d59-4cfb-a095-ce75013bb73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* MODEL METRIC REPORT *********\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "TP  FN\n",
      "FP  TN\n",
      "\n",
      "1082    300\n",
      "316    302\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Consent       0.77      0.78      0.78      1382\n",
      " Non-consent       0.50      0.49      0.50       618\n",
      "\n",
      "    accuracy                           0.69      2000\n",
      "   macro avg       0.64      0.64      0.64      2000\n",
      "weighted avg       0.69      0.69      0.69      2000\n",
      "\n",
      "Balanced accuracy: 0.64\n",
      "Accuracy: 0.69\n",
      "\n",
      "Actual consent rate: 69\n",
      "Predicted consent rate: 69\n"
     ]
    }
   ],
   "source": [
    "# predict DBD test data consent\n",
    "DBD_preds = dbd_gs_boost_model.predict(DBD_X_test)\n",
    "\n",
    "# print metrics\n",
    "show_metrics(DBD_y_test,DBD_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80c82386-b383-41d6-a839-05434cb38115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime = 4283.1minutes\n",
      "{'learning_rate': 0.25000000000000006, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.7012021321179738\n"
     ]
    }
   ],
   "source": [
    "# fit DCD model\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "dcd_gs_boost_model = GridSearchCV(cv_boost_model, param_grid=params, scoring=\"balanced_accuracy\",cv=5,n_jobs=3)\n",
    "\n",
    "dcd_gs_boost_model.fit(DCD_X_train,DCD_y_train)\n",
    "\n",
    "runtime = time.time() - start_time\n",
    "print(\"Runtime = {}minutes\".format(round(runtime/60,1)))\n",
    "\n",
    "dcd_gs_boost_model.score(DCD_X_train,DCD_y_train)\n",
    "\n",
    "print(dcd_gs_boost_model.best_params_)\n",
    "print(dcd_gs_boost_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c69514ca-a9ee-4ab1-bcce-03a46265e67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* MODEL METRIC REPORT *********\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "TP  FN\n",
      "FP  TN\n",
      "\n",
      "1471    394\n",
      "461    778\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Consent       0.76      0.79      0.77      1865\n",
      " Non-consent       0.66      0.63      0.65      1239\n",
      "\n",
      "    accuracy                           0.72      3104\n",
      "   macro avg       0.71      0.71      0.71      3104\n",
      "weighted avg       0.72      0.72      0.72      3104\n",
      "\n",
      "Balanced accuracy: 0.71\n",
      "Accuracy: 0.72\n",
      "\n",
      "Actual consent rate: 60\n",
      "Predicted consent rate: 62\n"
     ]
    }
   ],
   "source": [
    "DCD_preds = dcd_gs_boost_model.predict(DCD_X_test)\n",
    "\n",
    "# print metrics\n",
    "show_metrics(DCD_y_test,DCD_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200c7f43-e2e6-4af3-88be-847c7277e626",
   "metadata": {},
   "source": [
    "***\n",
    "#### Tuned DBD model\n",
    "Hyperparamter tuning the DBD boosted tree model has not increased the balanced accuracy, it's actually decreased it from 0.65 to 0.64. It has, however increased the recall for non-consents to 0.49 from 0.38 in the untuned model.  \n",
    "\n",
    "Despite the improvements on the untuned boosted forest model, the random forest model still performs better than the boosted forest model. The random forest is also much faster to run so it could be scaled to bigger datasets easier. \n",
    "\n",
    "#### Tuned DCD model\n",
    "The performance of the tuned DCD model is similar to the logistic regression. The non-consent recall is 0.63, 0.01 higher than the logistic regression and the balanced accuracy is 0.71 (equal to the logistic regression).  \n",
    "\n",
    "***\n",
    "\n",
    "### Conclusions\n",
    "\n",
    "For predicting family consent for organ donation in the DBD cohort a random forest model was deemed to have performed better than the logistic regression model, as it improved the balanced accuracy of the model and had a greater recall for non-consents, and only slightly reduced recall for consents. Despite this improvement, the overall accuracy was still deemed to not perform well enough to provide clinically useful results.  \n",
    "\n",
    "For predicting family consent in the DCD cohort no model performed better than the original logistic regression model.\n",
    "\n",
    "Overall, machine learning models could not improve on the previous logistic regression models enough to provide reliable predictions. This highlights the importance and benefits of improving data collection. \n",
    "\n",
    "This project did demonstrate the usefulness of machine learning models in this context due to the different characteristics of the models and their ability to be tuned and optimised for different metrics. \n",
    "\n",
    "Further work to build on this project could examine the importance of different variables in machine learning models and also how machine learning models compare when trained on more recent PDA datasets which include more variables which could improve the performance of the models.  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
