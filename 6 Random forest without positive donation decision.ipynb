{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56733ad6-2e01-440a-b1f2-ab5fdb36a2c2",
   "metadata": {},
   "source": [
    "# Random forest model without wish variable\n",
    "Author: Roddy Jaques <br>\n",
    "*NHS Blood and Transplant*\n",
    "***\n",
    "\n",
    "\n",
    "## Assessing the predictive ability of a random forest model without wish variable\n",
    "In this notebook random forest models will be fit to the DBD and DCD cohorts with the wish variable excluded.\n",
    "\n",
    "First load in the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "349c70cd-a4aa-4d91-b5ba-ffeb4c7594af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as mets\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "# Function to print confusion matrix, balanced accuracy and accuracy for a set of actual and predicted labels\n",
    "def show_metrics(actual,predict):\n",
    "    \"\"\" Prints the confusion matrix, balanced accuracy and accuracy given datasets of actual and predicted labels\n",
    "    \n",
    "    Arguments:\n",
    "        actual - Dataset of actual labels\n",
    "        predict - Dataset of predicted labels\n",
    "     \"\"\"\n",
    "    cm = mets.confusion_matrix(actual, predict)\n",
    "    \n",
    "    print(\"********* MODEL METRIC REPORT *********\\n\\nConfusion matrix:\\n\")\n",
    "\n",
    "    print(\"TP  FN\\nFP  TN\\n\") #this is a reminder of what each part of the confusion matrix means e.g. TP = True Positive\n",
    "    \n",
    "    # print the confusion matrix\n",
    "    print(str(int(cm[0,0])) + \"    \" + str(int(cm[0,1])))\n",
    "    print(str(int(cm[1,0])) + \"    \" + str(int(cm[1,1])) + \"\\n\") \n",
    "\n",
    "    # classification report for DBD model\n",
    "    print(\"Classification report:\\n\")\n",
    "    print(mets.classification_report(actual, predict))\n",
    "\n",
    "    print(\"Balanced accuracy: \" + str(round(mets.balanced_accuracy_score(actual, predict),2)))\n",
    "\n",
    "    print(\"Accuracy: \" + str(round(mets.accuracy_score(actual, predict),2)))\n",
    "    \n",
    "    # Predicted vs actual consent rates\n",
    "    cons_rate = int(100 * len(actual[actual==\"Consent\"]) / len(actual) )\n",
    "    print(\"\\nActual consent rate: \" + str(cons_rate))\n",
    "    \n",
    "    pred_rate = int(100 * len(predict[predict==\"Consent\"]) / len(predict) )\n",
    "    print(\"Predicted consent rate: \" + str(pred_rate))\n",
    "    \n",
    "    pass\n",
    " \n",
    "# Function to format consent column from integer code to text\n",
    "def format_consent(x):\n",
    "    if x == 2:\n",
    "        return \"Consent\"\n",
    "    if x == 1:\n",
    "        return \"Non-consent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2971600f-bfdd-4da6-84a6-99da4e72fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in datasets \n",
    "dbd_model_data = pd.read_csv(\"Data/dbd_model_data.csv\")\n",
    "dcd_model_data = pd.read_csv(\"Data/dcd_model_data.csv\")\n",
    "\n",
    "# Columns used to create DBD model\n",
    "dbd_cols = [\"FORMAL_APR_WHEN\", \"donation_mentioned\", \"app_nature\", \"eth_grp\", \"religion_grp\", \"GENDER\", \"FAMILY_WITNESS_BSDT\", \"DTC_PRESENT_BSD_CONV\", \n",
    "            \"acorn_new\", \"adult\",\"FAMILY_CONSENT\"]\n",
    "\n",
    "dbd_model_data2 = pd.get_dummies(data=dbd_model_data,columns=dbd_cols[:-1],drop_first=True)\n",
    "\n",
    "dbd_features = dbd_model_data2.drop(\"FAMILY_CONSENT\",axis=1)\n",
    "dbd_consents = dbd_model_data2[\"FAMILY_CONSENT\"].apply(format_consent)\n",
    "\n",
    "# Columns used to create DCD model in paper\n",
    "dcd_cols = [\"donation_mentioned\", \n",
    "            \"app_nature\", \"eth_grp\", \"religion_grp\", \"GENDER\", \"DTC_WD_TRTMENT_PRESENT\", \n",
    "            \"acorn_new\", \"adult\",\"cod_neuro\",\"FAMILY_CONSENT\"]\n",
    "\n",
    "dcd_model_data2 = pd.get_dummies(data=dcd_model_data,columns=dcd_cols[:-1],drop_first=True)\n",
    "\n",
    "dcd_features = dcd_model_data2.drop(\"FAMILY_CONSENT\",axis=1)\n",
    "dcd_consents = dcd_model_data2[\"FAMILY_CONSENT\"].apply(format_consent)\n",
    "\n",
    "# creating a train and testing dataset for DBD and DCD approaches\n",
    "DBD_X_train, DBD_X_test, DBD_y_train, DBD_y_test = train_test_split(dbd_features,dbd_consents, test_size=0.33, random_state=10)\n",
    "\n",
    "DCD_X_train, DCD_X_test, DCD_y_train, DCD_y_test = train_test_split(dcd_features,dcd_consents, test_size=0.33, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f5347f-cbdd-48c8-a446-5933099aed3c",
   "metadata": {},
   "source": [
    "## Model fitting\n",
    "This model will be fit with hyperparameter tuning as in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e45d53a0-0e94-4848-a18c-83cd0dbaa171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime = 11.6minutes\n",
      "{'class_weight': {'Non-consent': 2.25, 'Consent': 1}, 'max_depth': 26, 'min_samples_split': 127, 'n_estimators': 40}\n",
      "0.7422856352745104\n"
     ]
    }
   ],
   "source": [
    "cv_forest_model = RandomForestClassifier(random_state=66)\n",
    "\n",
    "# create list of dictionaries with weighting on Non-consent class\n",
    "weights = []\n",
    "for w in np.arange(2,4,step=0.25):\n",
    "    w_dic = {\"Non-consent\":w,\"Consent\":1}\n",
    "    weights.append(w_dic)\n",
    "\n",
    "# dictionary of hyperparameter values to be explored\n",
    "params = {'max_depth':np.arange(1,200,step=25),'min_samples_split':np.arange(2,200,step=25),'class_weight':weights,'n_estimators':np.arange(10,100,step=10)}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# train and fit model using cross validated grid search\n",
    "dbd_gs_forest_model = GridSearchCV(cv_forest_model, param_grid=params, scoring=\"balanced_accuracy\",cv=5,n_jobs=3)\n",
    "\n",
    "dbd_gs_forest_model.fit(DBD_X_train,DBD_y_train)\n",
    "\n",
    "# calculate run time\n",
    "runtime = time.time() - start_time\n",
    "print(\"Runtime = {}minutes\".format(round(runtime/60,1)))\n",
    "\n",
    "# show hyperparams and balanced accuracy for model with best balanced accuracy\n",
    "dbd_gs_forest_model.score(DBD_X_train,DBD_y_train)\n",
    "\n",
    "print(dbd_gs_forest_model.best_params_)\n",
    "print(dbd_gs_forest_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ccf8ecd-e838-49ff-85db-bff5fccc1760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* MODEL METRIC REPORT *********\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "TP  FN\n",
      "FP  TN\n",
      "\n",
      "968    414\n",
      "128    490\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Consent       0.88      0.70      0.78      1382\n",
      " Non-consent       0.54      0.79      0.64       618\n",
      "\n",
      "    accuracy                           0.73      2000\n",
      "   macro avg       0.71      0.75      0.71      2000\n",
      "weighted avg       0.78      0.73      0.74      2000\n",
      "\n",
      "Balanced accuracy: 0.75\n",
      "Accuracy: 0.73\n",
      "\n",
      "Actual consent rate: 69\n",
      "Predicted consent rate: 54\n"
     ]
    }
   ],
   "source": [
    "DBD_preds = dbd_gs_forest_model.predict(DBD_X_test)\n",
    "\n",
    "show_metrics(DBD_y_test,DBD_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eb9376b-8e47-4a23-9ebd-127ea2c910ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime = 14.6minutes\n",
      "{'class_weight': {'Non-consent': 2.0, 'Consent': 1}, 'max_depth': 26, 'min_samples_split': 52, 'n_estimators': 60}\n",
      "0.7264163916391639\n"
     ]
    }
   ],
   "source": [
    "# repeat for DCD cohort\n",
    "start_time = time.time()\n",
    "\n",
    "dcd_gs_forest_model = GridSearchCV(cv_forest_model, param_grid=params, scoring=\"balanced_accuracy\",cv=5,n_jobs=3)\n",
    "\n",
    "dcd_gs_forest_model.fit(DCD_X_train,DCD_y_train)\n",
    "\n",
    "runtime = time.time() - start_time\n",
    "print(\"Runtime = {}minutes\".format(round(runtime/60,1)))\n",
    "\n",
    "dcd_gs_forest_model.score(DCD_X_train,DCD_y_train)\n",
    "\n",
    "print(dcd_gs_forest_model.best_params_)\n",
    "print(dcd_gs_forest_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45088b20-6ded-4845-8d96-5833477a3736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* MODEL METRIC REPORT *********\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "TP  FN\n",
      "FP  TN\n",
      "\n",
      "1066    799\n",
      "168    1071\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Consent       0.86      0.57      0.69      1865\n",
      " Non-consent       0.57      0.86      0.69      1239\n",
      "\n",
      "    accuracy                           0.69      3104\n",
      "   macro avg       0.72      0.72      0.69      3104\n",
      "weighted avg       0.75      0.69      0.69      3104\n",
      "\n",
      "Balanced accuracy: 0.72\n",
      "Accuracy: 0.69\n",
      "\n",
      "Actual consent rate: 60\n",
      "Predicted consent rate: 39\n"
     ]
    }
   ],
   "source": [
    "DCD_preds = dcd_gs_forest_model.predict(DCD_X_test)\n",
    "\n",
    "show_metrics(DCD_y_test,DCD_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dcece3-0b5d-4a4a-873d-df4d6805eb61",
   "metadata": {},
   "source": [
    "***\n",
    "#### DBD model\n",
    "The balanced accuracy for this model is 0.75, the same as the random forest model with the wish variable included. The recall for the consent call is 0.70 and for the non-consent class it is 0.79. There's still a difference between the recall for each class but they are more balanced than the random forest including the wish variable. \n",
    "\n",
    "The predicted consent rate is closer to the actual consent rate than it was for the random forest model with the wish variable included.\n",
    "\n",
    "#### DCD model\n",
    "There are small differences in the metrics for this model compared to the random forest with the wish variable included, but none more than 0.02 and the balanced accuracy is the same. Removing the wish variable has not balanced the recall of the consent and non-consent classes as it did with the DBD cohort.\n",
    "\n",
    "***\n",
    "\n",
    "Removing the wish variable did balance the ability of the random forest to predict consents and non-consents for the DBD cohort, but had a minimal effect on the DCD cohort. This result is in agreement with the odds ratios from the logistic regression in notebook 1, where the odds ratios for the wish variable are lower in the DCD cohort, showing a weaker effect of this variable on consent than for the DCD cohort\n",
    "\n",
    "The next notebook will use a gradient boosted tree method to try and improve the model. Given the mixed results of removing the wish variable and to enable a fairer comparison with other models, the wish variable will be included in the gradient boosted model.\n",
    "\n",
    "***\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
